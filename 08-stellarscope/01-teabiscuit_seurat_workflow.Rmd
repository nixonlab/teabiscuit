---
title: "Load stellarscope data"
author: "Matthew Bendall"
date: "2023-05-24"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(scopetools)
library(Seurat)
library(patchwork)
library(magrittr)
```
## Load data

### Load STAR and stellarscope data into a Seurat object

If you look in this directory you will see two directories, `starsolo_out` and
`stellarscope_out`. These directories contain the outputs running the
stellarscope workflow.

To learn more about a function, you can type `?` before the function name to
give you the help pages. Lets learn about `scopetools::load_stellarscope_seurat`

We need to provide `stellarscope_dir` and  `starsolo_dir`, as well as the
`exp_tag` you specified when running **stellarscope**.

```{r load_stellarscope_seurat}
sobj <- scopetools::load_stellarscope_seurat(
    "stellarscope_out",
    starsolo_dir = "starsolo_out/Solo.out/Gene/filtered",
    exp_tag = "stellarscope",
    project = "teabiscuit"
)
```

You may explore the Seurat object a bit.

### Perform quality control on cells

Again, lets look at the help page for `scopetools::stellarscope_cell_qc`

```{r}
sobj <- scopetools::stellarscope_cell_qc(sobj)
```

Save the QC'd Seurat object

```{r}
saveRDS(sobj, 'sobj.qc.rds')
```


## Seurat workflow

### Data normalization

After removing unwanted cells from the dataset, the next step is to normalize the data. By default, we employ a global-scaling normalization method “LogNormalize” that normalizes the feature expression measurements for each cell by the total expression, multiplies this by a scale factor (10,000 by default), and log-transforms the result. Normalized values are stored in pbmc[["RNA"]]@data.

```{r}
sobj <- Seurat::NormalizeData(sobj)
```
### Identify variable features

We next calculate a subset of features that exhibit high cell-to-cell variation in the dataset (i.e, they are highly expressed in some cells, and lowly expressed in others). We and others have found that focusing on these genes in downstream analysis helps to highlight biological signal in single-cell datasets.

Our procedure in Seurat is described in detail here, and improves on previous versions by directly modeling the mean-variance relationship inherent in single-cell data, and is implemented in the FindVariableFeatures() function. By default, we return 2,000 features per dataset. These will be used in downstream analysis, like PCA.

```{r}
sobj <- Seurat::FindVariableFeatures(sobj)
```

```{r}
# Identify the 10 most highly variable genes
top10 <- head(VariableFeatures(sobj), 10)
data.frame(genename=top10)
```

```{r fig.height=10, fig.width=12}
# plot variable features with and without labels
plot1 <- VariableFeaturePlot(sobj)
plot2 <- LabelPoints(plot = plot1, points = top10, repel = TRUE)
plot1 + plot2
```

```{r}
varfeattable <- sobj[['RNA']]@meta.features[VariableFeatures(sobj),]
table(varfeattable$te_class, useNA = 'ifany')
```

#### Variable HERVs

```{r}
varfeattable %>%
    dplyr::filter(te_class=='LTR') %>%
    dplyr::arrange(-vst.variance.standardized)
```

### Scaling the data

Next, we apply a linear transformation (‘scaling’) that is a standard pre-processing step prior to dimensional reduction techniques like PCA. The ScaleData() function:

Shifts the expression of each gene, so that the mean expression across cells is 0
Scales the expression of each gene, so that the variance across cells is 1
This step gives equal weight in downstream analyses, so that highly-expressed genes do not dominate
The results of this are stored in sobj[["RNA"]]@scale.data

```{r}
sobj <- ScaleData(sobj)
```

Scaling is an essential step in the Seurat workflow, but only on genes that will be used as input to PCA. Therefore, the default in ScaleData() is only to perform scaling on the previously identified variable features (2,000 by default). Your PCA and clustering results will be unaffected. However, Seurat heatmaps (produced as shown below with DoHeatmap()) require genes in the heatmap to be scaled, to make sure highly-expressed genes don’t dominate the heatmap. 

To save time, we are only scaling highly variable genes in this tutorial.

We are going to save this object before doing any dimensional reduction.

```{r}
saveRDS(sobj, 'sobj.scaled.rds')
```


### Perform linear dimensional reduction

Next we perform PCA on the scaled data. By default, only the previously determined variable features are used as input, but can be defined using features argument if you wish to choose a different subset.

```{r}
sobj <- RunPCA(sobj, features=VariableFeatures(sobj))
DimPlot(sobj, reduction = "pca")
```

### Cluster the cells

Seurat v3 applies a graph-based clustering approach, building upon initial strategies in (Macosko et al). Importantly, the distance metric which drives the clustering analysis (based on previously identified PCs) remains the same. However, our approach to partitioning the cellular distance matrix into clusters has dramatically improved. Our approach was heavily inspired by recent manuscripts which applied graph-based clustering approaches to scRNA-seq data [SNN-Cliq, Xu and Su, Bioinformatics, 2015] and CyTOF data [PhenoGraph, Levine et al., Cell, 2015]. Briefly, these methods embed cells in a graph structure - for example a K-nearest neighbor (KNN) graph, with edges drawn between cells with similar feature expression patterns, and then attempt to partition this graph into highly interconnected ‘quasi-cliques’ or ‘communities’.

As in PhenoGraph, we first construct a KNN graph based on the euclidean distance in PCA space, and refine the edge weights between any two cells based on the shared overlap in their local neighborhoods (Jaccard similarity). This step is performed using the FindNeighbors() function, and takes as input the previously defined dimensionality of the dataset (first 10 PCs).

To cluster the cells, we next apply modularity optimization techniques such as the Louvain algorithm (default) or SLM [SLM, Blondel et al., Journal of Statistical Mechanics], to iteratively group cells together, with the goal of optimizing the standard modularity function. The FindClusters() function implements this procedure, and contains a resolution parameter that sets the ‘granularity’ of the downstream clustering, with increased values leading to a greater number of clusters. We find that setting this parameter between 0.4-1.2 typically returns good results for single-cell datasets of around 3K cells. Optimal resolution often increases for larger datasets. The clusters can be found using the Idents() function.

```{r}
sobj <- FindNeighbors(sobj, dims = 1:10)
```

```{r}
sobj <- FindClusters(sobj, resolution = 0.5)
```
### Run non-linear dimensional reduction (UMAP/tSNE)

Seurat offers several non-linear dimensional reduction techniques, such as tSNE and UMAP, to visualize and explore these datasets. The goal of these algorithms is to learn the underlying manifold of the data in order to place similar cells together in low-dimensional space. Cells within the graph-based clusters determined above should co-localize on these dimension reduction plots. As input to the UMAP and tSNE, we suggest using the same PCs as input to the clustering analysis.

```{r}
sobj <- RunUMAP(sobj, dims = 1:10)

```

```{r}
DimPlot(sobj, reduction = "umap")
```
Lets save again

```{r}
saveRDS(sobj, "sobj.final_1.rds")

```

### Finding differentially expressed features (cluster biomarkers)

Seurat can help you find markers that define clusters via differential expression. By default, it identifies positive and negative markers of a single cluster (specified in ident.1), compared to all other cells. FindAllMarkers() automates this process for all clusters, but you can also test groups of clusters vs. each other, or against all cells.

The min.pct argument requires a feature to be detected at a minimum percentage in either of the two groups of cells, and the thresh.test argument requires a feature to be differentially expressed (on average) by some amount between the two groups. You can set both of these to 0, but with a dramatic increase in time - since this will test a large number of features that are unlikely to be highly discriminatory. As another option to speed up these computations, max.cells.per.ident can be set. This will downsample each identity class to have no more cells than whatever this is set to. While there is generally going to be a loss in power, the speed increases can be significant and the most highly differentially expressed features will likely still rise to the top.


```{r}
sobj.markers <- FindAllMarkers(sobj)
```

```{r}
saveRDS(sobj.markers, "sobj.markers.Rds")
```

```{r}
tt <- sobj.markers %>%
    dplyr::group_by(cluster) %>%
    dplyr::slice_max(n=5, order_by=avg_log2FC)

tt$rn <- make.unique(tt$gene, sep=".")
tt %<>% tibble::column_to_rownames("rn")
tt
```

```{r}
pdf('01-teabiscuit_seurat_workflow.featureplot.pdf', width=45, height=45)
FeaturePlot(sobj, features=tt$gene)
dev.off()

```